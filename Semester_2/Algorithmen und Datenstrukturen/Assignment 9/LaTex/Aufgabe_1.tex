\section{Problem: Suchen in Zeichenketten I}

Implementieren Sie den naiven Algorithmus und den Algorithmus von Rabin-Karp
zur Suche in Zeichenketten. Finden Sie dann heraus, wie oft das Wort whale in Moby
Dick vorkommt (ignorieren Sie dabei Groß- und Kleinschreibung). Wie schneiden
Ihre Implementierungen im Vergleich ab?
Hinweis: Den Roman Moby Dick finden Sie unter\\
http://www.gutenberg.org/files/2701/2701-0.txt.

\subsection{Implementierung:}

\lstinputlisting[language=Python]{./Code/Suchen_in_Zeichenketten_l.py}

\newpage
\subsection{Auswertung:}
Beide Algorithmen finden den substring "whale" 1702 mal und 529 mal den string "whale" im Buch Moby Dick. Einen merkbaren Unterschied für die Laufzeit bzw. Berechnungszeit der Algorithmen konnten wir (auf unseren Systemen/ Rechnern) nicht feststellen. 

Laufzeitkomplexität naiver Algorithmus: $O(k·l*|mb|) \rightarrow O(k·l)$ ist der Average-case des naiven Algorithmus, wobei $k$ die Länge des aktuellen Strings ist und $l$ die Länge des gesuchten Substrings. $|mb|$ ist die Länge des Buches Moby Dick. Laufzeitkomplexität Rabin-Karp Algorithmus: $O(|mb|*(k+l)) \rightarrow O(k+l)$ ist der Average-case des Rabin-Karp Algorithmus, wobei $k$ die Länge des aktuellen Strings ist und $l$ die Länge des gesuchten Substrings. $|mb|$ ist die Länge des Buches Moby Dick. Obwohl ein theoretischer Unterschied besteht, ist das Buch Moby Dick nicht lang genug, um diesen deutlich zumachen. Im Fall von Moby Dick bewegen sich die Unterschiede im nano- bis Millisekunden Bereich (auf unseren Systemen).